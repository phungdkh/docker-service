input {
    
    rabbitmq {
        type => "analytic"
        host => "rabbitmq"
        queue => "analytic_queue"
        exchange => "analytic_exchange"
        exchange_type => "direct"
        heartbeat => 30
        key => "analytic"
        durable => true
        user => "${RABBITMQ_USERNAME:username}"
        password => "${RABBITMQ_PASSWORD:password}"
    }
}

output {
      # Must use type to filter incoming, else 3 messages (event, command, analytic)
      # will be written to MongoDB. Reason is that Docker image config does not 
      # support running in multiple pipeline mode. It means that all defined 
      # output commands get a copy of incoming message regardless of what queue was source
      # of message.... Quite annoying :( 

      if [type] == "analytic" {

      #  stdout { codec => rubydebug }

        elasticsearch {
            hosts => "elasticsearch:9200"
            index => "datahub-%{+YYYY.MM.dd}"
        }

        mongodb {
            collection => "analytic"
            database => "datahub"
            uri => "mongodb://mongodb:27017/datahub"        
            codec => "json"
        }
    }
}